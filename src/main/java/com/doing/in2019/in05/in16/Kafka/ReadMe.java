package com.doing.in2019.in05.in16.Kafka;

public class ReadMe {

	/**
	 * Kafka
	 * 
	 * 		“普通”的服务器，Kafka也可以轻松支持每秒百万级的写入请求，这种特性使得Kafka在日志处理等海量数据场景广泛应用。
	 * 		针对Kafka的基准测试可以参考，Apache Kafka基准测试：每秒写入2百万（在三台廉价机器上）。
	 * 
	 * 		写入高性能分析：
	 * 			1.为了提高读写硬盘的速度，Kafka使用顺序I/O，顺序写入磁盘，并且掉电还有持久化数据。
	 * 				磁盘读写的快慢取决于你怎么使用它，也就是顺序读写或者随机读写。在顺序读写的情况下，磁盘的顺序读写速度和内存持平。
	 * 				因为硬盘是机械结构，每次读写都会寻址->写入，其中寻址是一个“机械动作，磁头读磁盘”，它是最耗时的。
	 * 				所以硬盘最讨厌随机I/O，最喜欢顺序I/O。
	 * 				注意---1.kafka的这种方法有一个缺陷，没有办法删除数据
	 * 					  2.如果不删除硬盘肯定会被撑满，所以Kakfa提供了两种策略来删除数据：1、顺序写入一是基于时间	2、顺序写入二是基于partition文件大小。
	 * 
	 * 			2.即便是顺序写入硬盘，硬盘的访问速度还是不可能追上内存。所以Kafka的数据并不是实时的写入硬盘 ，它充分利用了现代操作系统分页存储来利用内存提高I/O效率。
	 * 				TODO ？不懂
	 * 
	 * 
	 * 		读取高性能分析：
	 * 			1.基于sendfile实现Zero Copy，零拷贝
	 * 				传统方式read/write传输文件，实质是经过了4次copy，内核缓冲区 → 用户缓冲区 → 内核与socket缓冲区 → 相关协议引擎
	 * 				基于sendfile的方式， 内核缓冲区 → 内核与socket缓冲区 → 协议引擎
	 * 
	 * 			2.批量压缩
	 * 				在很多情况下，系统的瓶颈不是CPU或磁盘，而是网络IO，对于需要在广域网上的数据中心之间发送消息的数据流水线尤其如此。
	 * 				进行数据压缩会消耗少量的CPU资源,不过对于kafka而言,网络IO更应该需要考虑。
	 * 
	 * 总结：
	 * 		Kafka速度的秘诀在于：
				1.它把所有的消息都变成一个批量的文件，
	 * 			2.并且进行合理的批量压缩，减少网络IO损耗，通过mmap提高I/O速度，
	 * 			3.写入数据的时候由于单个Partion是末尾添加所以速度最优；
	 * 			4.读取数据的时候配合sendfile直接暴力输出。
	 * 
	 * 注意---大家都说卡夫卡丢数据，要重传	 ( ﹁ ﹁ ) ~→
	 */
}